# Pilotproject
최초 작성일 : 2024-01-22  
마지막 수정일 : 2024-01-27
  
## 0. Overview

본 글에서는 프로젝트에 대한 전체적인 흐름과 결과물에 대해서만 정리할 것이다.
아래 내용는 프로젝트를 구성하고 수행하는 내용에 대해서만 작성을 하고, 관련된 용어와 프레임워크에 대한 설명은 각각 다른 문서에서 다룰 예정이다.
특히, 각 프레임워크의 필요한 구성에 대해서는 설명하되, 세부적인 문법에 대해서는 다른 문서에서 다룰 예정이다.


 
[프로젝트]에 대한 설명
빅데이터 수집을 구축하기에 앞서, 프로젝트 목적에 맞는 수집 요구 사항에 대해서 맨 처음 점검하였다.

|Requirements|Description|
|--|--|
|요구사항1|차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검|
|요구사항2|운전자의 운행 정보를 담긴 로그를 실시간으로 수집해서 주행패턴을 분석|

위 요구사항에 맞는 데이터 시스템을 구현하기 위해 아래와 같은 순서로 데이터 시스템을 구축한다.


## Table of Contents


1. [Big Data Collection](#1.-Big-Data-Collection)
2. [Big Data Ingestion (Loading Large Log Files)](#2.-Big-Data-Ingestion-(Loading-Large-Log-Files))
3. [Big Data Ingestion (Real-time Log/Analysis Loading)](#3.-Big-Data-Ingestion-(Real-time-Log/Analysis-Loading))
4. [Big Data Exploration](#4.-Big-Data-Exploration)
5. [Big Data Analysis](#5.-Big-Data-Analysis)
6. [Expanding Analytical Environment](#6.-Expanding-Analytical-Environment)

<!--
빅데이터 수집 
빅데이터 적재 : 대용량 로그 파일 적재 - 
빅데이터 적재 : 실시간 로그 /분석 적재 - 
빅데이터 탐색 
빅데이터 분석 
분석환경 확장 
-->




## 1. Big Data Collection
### 1.1. 주요 내용

위 요구 사항을 해결하기 위해, 수집 단계에 대한 세부 요구사항을 구체화하면, 아래 표와 같다.

|Specific Requirements|List to do|
|--|--|
|스마트카로부터 로그 파일들을 주기적으로 발생|플롬을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집|
|스마트카의 배치 로그 파일 이벤트를 감지|플럼의 Source 컴포넌트 중, SpoolDir을 이용해서 주기적인 로그 파일 발생 이벤트 감지|
|스마트카의 실시간 로그 발생 이벤트를 감지|플럼의 Source 컴포넌트 중, Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지|
|스마트카가 만들어내는 로그 데이터 중 가비지 데이터가  있을 가능성|플럼의 Interceptor를 이용해서 정상 패턴의 데이터만 필터링|
|수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재처리|플럼의 메모리 중 Channel 및 카프카 Broker 활용으로 로컬 디스크의 파일시스템에 수집 데이터 임시 저장|
|스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리|플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송|

따라서, 위 작업을 수행하기 위해, 먼저 flume과 kafka의 설치와 설정이 필요하였다. 해당 작업은 cloudera를 통해 쉽게 해결하였고, 데이터를 송수신 할 수 있도록, Agent를 구성하고, 기초적인 활용방법과 메커니즘에 대해 알아보았다.
Agent에 대한 세부적인 내용도 중요한 부분이긴 하지만, 프로젝트의 전체적인 흐름을 설명하는 이 문서에서는 너무 지엽적인 문제라 우선 삭제하였다.
각 프레임워크에 대한 활용 방법을 익히고, 실제 Java에 의한 로그 생성을 작동하여, 각 프레임워크가 데이터를 수집하는지 수집 기능 테스트를 수행하였다.

### 1.2. 결과물
왼쪽 화면 내, JAVA(.jar)에 의한 로그 시뮬레이터에서 로그파일을 실시간으로 생성하는 것이고, Kafka consumer를 통해 생성된 로그 파일을 수신하는 것 모습이다. 마지막 CLI 화면은 flumer이다.

오른쪽 화면 내, Cloudera Manager가 Cluster에 포함된 각종 Framework의 설치 및 실행, 상태에 대해 모니터링할 수 있도록 UI를 제공하고 있고, Framwork의 동작에 따라 컴퓨터와 서버의 자원도 모니터링 하여 사용자에게 정보를 제공한다.


![pilotproject_data_collection_result](./images/pilotproject_data_collection_result.gif)


### 1.3. 느낀점
- Cloudera를 사용하며, 각종 Framework와 아키텍처를 구성하는 것에 대해 매우 편리함을 느꼈다.
- 각 Framework 내 configuration를 정확하게 작성하기 위해서는 각 conponent와 agent가 수행하는 역할에 대해 올바르게 이해하고 있어야 한다.
- data, file을 어느 객체가 어디에서 어디로 전송하는지 이해하고, pipeline을 구축해야 한다.
- node, pipeline에 대해서는 사용자가 꼼꼼히 확인하여 입력해야하며, 이를 위해 데이터 엔지니어는 항상 구조를 이해하고 기억하고 있어야겠다는 생각을 했다.
- 생각보다 각 module 또는 agent 단위가 파일을 읽고, 쓰는 행위가 많다. 따라서, command line 입력 외에 대부분의 에러는 agent가 파일에 접근할 때 발생하는 에러일 것이라 예상한다.
 


## 2. Big Data Ingestion (Loading Large Log Files)  

데이터를 적재하기 위해서는 원천 데이터의 종류, 수집 주기, 적재 저장소 유형을 모두 고려해야 한다. 각 개념은 아래와 같이 구분된다.
적재에는 크게 2가지가 있는데, 대용량 파일을 적재하는 것과 실시간 메세지를 적재하는 것이 존재한다. 그리고 전자는 배치성 처리, 후자는 실시간성 처리라고 한다.
이에 대해 더 자세히 말하자면, 

|원천 데이터 유형|예시|
|--|--|
|정형 데이터|데이터 베이스(관계/계층/객체/네트워크)|
|반정형 데이터|HTML, XML, JSON, SERVER LOG|
|비정형 데이터|소셜 미디어, 문서, 이미지, 오디오, 비디오, 사물인터넷|

|수집 유형|저장소 유형|예시|
|--|--|--|
|배치성 수집|대용량 파일 전체 영구 저장|분산 파일 시스템|
|실시간 수집|대규모 메세지 전체 영구 저장|No-SQL|
|실시간 수집|대규모 메세지 전체 버퍼링 처리|MoM|
|실시간 수집|대규모 데이터 일부 임시 저장|Cached(In-memory)|



### 2.1. 주요 내용 

위 요구 사항을 적재에 맞게끔 아래와 같이 다시 정리할 수 있다.

|Specific Requirements|List to do|
|--|--|
|100대에 달하는 스마트카들의 상태 정보가 일 단위로 취합되어 제공|플럼에서 수집 발생 시점의 날짜를 HdfsSink에 전달해서 해당 날짜 단위로 적재|
|매일 100대의 스마트카 상태 정보는 약 100MB 정도이며, 220만 건의 상태 정보 발생|1년 적재 시 8억 건 이상의 데이터가 적재되며, 연 단위 분석에 하둡의 분산 병렬 처리 사용|
|스마트카의 상태 정보 데이터의 발생일과 수집/적재되는 날짜가 다를 가능성|수집/적재되는 모든 데이터마다 데이터 발생일 외에 수집/적재 처리돼야 하는 처리일 추가|
|적재된 스마트카들의 상태 정보를 일/월/년 단위로 분석해야함|HDFS에 수집 일자별로 디렉터리 경로를 만들어 적재|
|적재 및 생성되는 파일은 HDFS의 특징을 고려해야함|플럼의 HdfsSink의 옵션을 파일럿 프로젝트의 HDFS에 최적화하여 설정|
|적재가 완료된 후에는 원천 파일 삭제|플럼의 Source 컴포넌트 중 SpoolDir의 DeletePolicy 옵션 활용|






### 2.2. 결과물

이번 장에서는 빅데이터 대용량 파일 적재에 대한 기본 개념과 적재 수행을 위해서 Hadoop 내 HDFS, Flume, Zookeeper의 기능, 아키텍쳐에 대해 공부하고, 이를 활용하여 데이터 수집 프로세르를 구현하였다.

아래는 로그 시뮬레이터를 이용해서, 파일(SmartCarStatusInfo_20200102.txt)을 생성하고, Flume이 인식하여, 데이터를 수집할 수 있도록 /var/log/flume-ng/ 폴더로 옮겼다. 이 후, 아래 명령어를 통해 flume의 로그를 확인하여, 동작하는 것을 모니터링 하였다.
```
$ tail -f flume-cmf-flume-AGENT-server02.hadoop.com.log
```
![pilotproject_plume_operation1](./images/pilotproject_plume_operation1.png)

아래는 Flume을 통해 HDFS에 파일이 적재된 것을 확인하기 위해 hdfs 명령어를 활용하여, 파일과 파일 내 로그 데이터를 확인하였다.

```
# 로그 파일 확인
$ hdfs dfs -ls -R /pilot-pjt/collect/car-batch-log

# 하나의 로그 파일 데이터 확인
$ hdfs dfs -tail /pilot-pjt/collect/car-batch-log/wrk_date=20240128/car-batch-log.1706410302520.log
```







과 주키퍼의 주요 기능과 아키텍쳐, 활용 방법에 대해 공부하였다.
특히, 스마트카에서 발생하는 로그 파일 적재와 관련된 요구사항을 구체화하여, 적재 요건을 해결하기 위핸 파일럿 아키텍처를 알아보았다.
또한, 스마트카 로그 파일의 적재 아키텍처를 설치 및 환경 구성을 하였고, 플럼을 이용하여 스마트카의 상태 정보 로그 파일을 하둡에 적재하는 기능을 구현해보았다.

마지막으로 로그 시뮬레이터를 이용해 스마트카의 정보 데이터를 발생시키고, 플럼이 해당 데이터를 HDFS에 정상적으로 적재하는지 기능테스트를 해보았다.



