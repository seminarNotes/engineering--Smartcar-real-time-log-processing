# Pilotproject
최초 작성일 : 2024-01-22  
마지막 수정일 : 2024-01-27
  
## 0. Overview

본 글에서는 프로젝트에 대한 전체적인 흐름과 결과물에 대해서만 정리할 것이다.
아래 내용는 프로젝트를 구성하고 수행하는 내용에 대해서만 작성을 하고, 관련된 용어와 프레임워크에 대한 설명은 각각 다른 문서에서 다룰 예정이다.
특히, 각 프레임워크의 필요한 구성에 대해서는 설명하되, 세부적인 문법에 대해서는 다른 문서에서 다룰 예정이다.

프로젝트에서 가장 중요한 것은 구현하고자하는 요구사항을 올바르게 이해하고, 구체화하여, 아키텍처를 구성하고, 구조와 관련된 SW/Framework를 올바르게 사용하는 것이다. 따라서, 글에서는 세부적인 SW/Framework에 대한 설명을 최소화고 하고, 프로젝트 구조와 흐름에 대해 설명을 할 것이다.

 
[프로젝트]에 대한 설명
빅데이터 수집을 구축하기에 앞서, 프로젝트 목적에 맞는 수집 요구 사항에 대해서 맨 처음 점검하였다.

|Requirements|Description|
|--|--|
|요구사항1|차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검|
|요구사항2|운전자의 운행 정보를 담긴 로그를 실시간으로 수집해서 주행패턴을 분석|

위 요구사항에 맞는 데이터 시스템을 구현하기 위해 아래와 같은 순서로 데이터 시스템을 구축한다.


## Table of Contents


1. [Big Data Collection](#1.-Big-Data-Collection)
2. [Big Data Ingestion (Loading Large Log Files)](#2.-Big-Data-Ingestion-(Loading-Large-Log-Files))
3. [Big Data Ingestion (Real-time Log/Analysis Loading)](#3.-Big-Data-Ingestion-(Real-time-Log/Analysis-Loading))
4. [Big Data Exploration](#4.-Big-Data-Exploration)
5. [Big Data Analysis](#5.-Big-Data-Analysis)
6. [Expanding Analytical Environment](#6.-Expanding-Analytical-Environment)

<!--
빅데이터 수집 
빅데이터 적재 : 대용량 로그 파일 적재 - 
빅데이터 적재 : 실시간 로그 /분석 적재 - 
빅데이터 탐색 
빅데이터 분석 
분석환경 확장 
-->




## 1. Big Data Collection
### 1.1. 주요 내용

위 요구 사항을 해결하기 위해, 수집 단계에 대한 세부 요구사항을 구체화하면, 아래 표와 같다.

|Specific Requirements|List to do|
|--|--|
|스마트카로부터 로그 파일들을 주기적으로 발생|플롬을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집|
|스마트카의 배치 로그 파일 이벤트를 감지|플럼의 Source 컴포넌트 중, SpoolDir을 이용해서 주기적인 로그 파일 발생 이벤트 감지|
|스마트카의 실시간 로그 발생 이벤트를 감지|플럼의 Source 컴포넌트 중, Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지|
|스마트카가 만들어내는 로그 데이터 중 가비지 데이터가  있을 가능성|플럼의 Interceptor를 이용해서 정상 패턴의 데이터만 필터링|
|수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재처리|플럼의 메모리 중 Channel 및 카프카 Broker 활용으로 로컬 디스크의 파일시스템에 수집 데이터 임시 저장|
|스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리|플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송|

따라서, 위 작업을 수행하기 위해, 먼저 flume과 kafka의 설치와 설정이 필요하였다. 해당 작업은 cloudera를 통해 쉽게 해결하였고, 데이터를 송수신 할 수 있도록, Agent를 구성하고, 기초적인 활용방법과 메커니즘에 대해 알아보았다.
Agent에 대한 세부적인 내용도 중요한 부분이긴 하지만, 프로젝트의 전체적인 흐름을 설명하는 이 문서에서는 너무 지엽적인 문제라 우선 삭제하였다.
각 프레임워크에 대한 활용 방법을 익히고, 실제 Java에 의한 로그 생성을 작동하여, 각 프레임워크가 데이터를 수집하는지 수집 기능 테스트를 수행하였다.

### 1.2. 결과물
왼쪽 화면 내, JAVA(.jar)에 의한 로그 시뮬레이터에서 로그파일을 실시간으로 생성하는 것이고, Kafka consumer를 통해 생성된 로그 파일을 수신하는 것 모습이다. 마지막 CLI 화면은 flumer이다.

오른쪽 화면 내, Cloudera Manager가 Cluster에 포함된 각종 Framework의 설치 및 실행, 상태에 대해 모니터링할 수 있도록 UI를 제공하고 있고, Framwork의 동작에 따라 컴퓨터와 서버의 자원도 모니터링 하여 사용자에게 정보를 제공한다.


![pilotproject_data_collection_result](./images/pilotproject_data_collection_result.gif)


### 1.3. 느낀점
- Cloudera를 사용하며, 각종 Framework와 아키텍처를 구성하는 것에 대해 매우 편리함을 느꼈다.
- 각 Framework 내 configuration를 정확하게 작성하기 위해서는 각 conponent와 agent가 수행하는 역할에 대해 올바르게 이해하고 있어야 한다.
- data, file을 어느 객체가 어디에서 어디로 전송하는지 이해하고, pipeline을 구축해야 한다.
- node, pipeline에 대해서는 사용자가 꼼꼼히 확인하여 입력해야하며, 이를 위해 데이터 엔지니어는 항상 구조를 이해하고 기억하고 있어야겠다는 생각을 했다.
- 생각보다 각 module 또는 agent 단위가 파일을 읽고, 쓰는 행위가 많다. 따라서, command line 입력 외에 대부분의 에러는 agent가 파일에 접근할 때 발생하는 에러일 것이라 예상한다.
 


## 2. Big Data Ingestion (Loading Large Log Files)  

데이터를 적재하기 위해서는 원천 데이터의 종류, 수집 주기, 적재 저장소 유형을 모두 고려해야 한다. 각 개념은 아래와 같이 구분된다.
적재에는 크게 2가지가 있는데, 대용량 파일을 적재하는 것과 실시간 메세지를 적재하는 것이 존재한다. 그리고 전자는 배치성 처리, 후자는 실시간성 처리라고 한다.
이에 대해 더 자세히 말하자면, 

|원천 데이터 유형|예시|
|--|--|
|정형 데이터|데이터 베이스(관계/계층/객체/네트워크)|
|반정형 데이터|HTML, XML, JSON, SERVER LOG|
|비정형 데이터|소셜 미디어, 문서, 이미지, 오디오, 비디오, 사물인터넷|

|수집 유형|저장소 유형|예시|
|--|--|--|
|배치성 수집|대용량 파일 전체 영구 저장|분산 파일 시스템|
|실시간 수집|대규모 메세지 전체 영구 저장|No-SQL|
|실시간 수집|대규모 메세지 전체 버퍼링 처리|MoM|
|실시간 수집|대규모 데이터 일부 임시 저장|Cached(In-memory)|



### 2.1. 주요 내용 

위 요구 사항을 적재에 맞게끔 아래와 같이 다시 정리할 수 있다.

|Specific Requirements|List to do|
|--|--|
|100대에 달하는 스마트카들의 상태 정보가 일 단위로 취합되어 제공|플럼에서 수집 발생 시점의 날짜를 HdfsSink에 전달해서 해당 날짜 단위로 적재|
|매일 100대의 스마트카 상태 정보는 약 100MB 정도이며, 220만 건의 상태 정보 발생|1년 적재 시 8억 건 이상의 데이터가 적재되며, 연 단위 분석에 하둡의 분산 병렬 처리 사용|
|스마트카의 상태 정보 데이터의 발생일과 수집/적재되는 날짜가 다를 가능성|수집/적재되는 모든 데이터마다 데이터 발생일 외에 수집/적재 처리돼야 하는 처리일 추가|
|적재된 스마트카들의 상태 정보를 일/월/년 단위로 분석해야함|HDFS에 수집 일자별로 디렉터리 경로를 만들어 적재|
|적재 및 생성되는 파일은 HDFS의 특징을 고려해야함|플럼의 HdfsSink의 옵션을 파일럿 프로젝트의 HDFS에 최적화하여 설정|
|적재가 완료된 후에는 원천 파일 삭제|플럼의 Source 컴포넌트 중 SpoolDir의 DeletePolicy 옵션 활용|

### 2.2. 결과물

이번 장에서는 빅데이터 대용량 파일 적재에 대한 기본 개념과 적재 수행을 위해서 Hadoop 내 HDFS, Flume, Zookeeper의 기능, 아키텍쳐에 대해 공부하고, 이를 활용하여 데이터 수집 프로세르를 구현하였다.

아래는 로그 시뮬레이터를 이용해서, 파일(SmartCarStatusInfo_20200102.txt)을 생성하고, Flume이 인식하여, 데이터를 수집할 수 있도록 /var/log/flume-ng/ 폴더로 옮겼다. 이 후, 아래 명령어를 통해 flume의 로그를 확인하여, 동작하는 것을 모니터링 하였다.
```
$ tail -f flume-cmf-flume-AGENT-server02.hadoop.com.log
```
![pilotproject_plume_operation1](./images/pilotproject_plume_operation1.png)

아래는 Flume을 통해 HDFS에 파일이 적재된 것을 확인하기 위해 hdfs 명령어를 활용하여, 파일과 파일 내 로그 데이터를 확인하였다.

```
# 로그 파일 확인
$ hdfs dfs -ls -R /pilot-pjt/collect/car-batch-log

# 하나의 로그 파일 데이터 확인
$ hdfs dfs -tail /pilot-pjt/collect/car-batch-log/wrk_date=20240128/car-batch-log.1706410302520.log
```
정상적으로 파일과 데이터가 적재되었음을 확인함으로써, Flume의 이벤트 작동과 적재 기능 테스트를 완료하였다. 이 후, Framework와 서버를 종료하였다.
![pilotproject_plume_operation1](./images/pilotproject_plume_operation2.png)

### 2.3. 느낀점  
- CLI로 이루어진 프로그램에서 로그를 꼼꼼히 읽어야 한다는 점을 문득 느끼게 되었다.
- 4번을 통해 성공적으로 해당 단계를 완료하였으며, 중간에 Flume에 대한 로그를 확인하였을 때, 대게 5분 정도 소요되는 작업이 아래와 같은 화면의 상태로 8시간 이상 되어도 동작이 수행되지 않는 트러블 슈팅이 있었다. 해당 트러블 슈팅은 Cloudera에서 모든 Framework를 완전히 종료(정지)하고, Server를 저장하고, 컴퓨터 재부팅 후, 다시 시도하여 해결하였다. 정확한 원인을 파악하지 못하였지만, 구성 파일(.conf) 업데이트 후, flume의 재시작 시, 구성이 재대로 반영되지 않은 부분이라 추측하고 있다.
![pilotproject_plume_operation1](./images/pilotproject_plume_operation_error.png)




## 3. Big Data Ingestion (Real-time Log/Analysis Loading)   

실시간 데이터 처리가 높은 난이도를 갖는 이유는 다음과 같다.
먼저, 실시간 데이터는 데이터가 빠른 속도로 발생하고, 오랜 시간에 걸쳐 발생하고, 대규모로 발생한다는 점이다.
둘째, 실시간으로 발생하는 데이터를 반영한 처리하고, 분석하는 아키텍처를 고민해야 한다
셋째, 하루에 약 수억개의 데이터가 발생하는 것이 보통이기에 일반적인 데이터베이스를 사용하는 경우, 오버헤드 에러가 발생할 수 있다. 따라서, 상황과 조건에 맞는 적절한 프레임워크나 데이터베이스를 조사하여 선택해야한다.
마지막으로, 에러/장애가 발생하는 경우, 복구가 되더라도 상당한 양의 데이터 유실이 발생한다. 이러한 상황을 어떻게 대비할 것인지에 대해 예외처리를 고려해야한다.

이러한 실시간 수집을 위해 사용하는 데이터베이스(저장소)는 다음과 같다.

|수집 유형|저장소 유형|예시|
|--|--|--|
|실시간 수집|대규모 메세지 전체 영구 저장|No-SQL|
|실시간 수집|대규모 메세지 전체 버퍼링 처리|MoM|
|실시간 수집|대규모 데이터 일부 임시 저장|Cached(In-memory)|

### 3.1. 주요 내용
위 요구사항은 이번 단계에서는 "요구사항 2: 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행패턴을 분석한다"에 대해 아키텍쳐를 구성하고, 구현한다. 먼저, 해당 요구사항을 구체화 하면 아래 표와 같다.

|Specific Requirements|List to do|
|--|--|
|1초 간격으로 발생하는 100명의 운행 정보(운행 정보 1건 : 약 4KB)는 손실 없이 적재해야 한다.|카프카와 스톰을 이용해 수집한 데이터에 대해 분산 처리 및 무결성을 보장하며, 분산 처리가 완료된 데이터는 HBase에 적재|
|적재한 운행 정보를 대상으로 조건 검색이 가능해야 하며, 필요 시 수정도 가능해야 한다.|HBase의 테이블에 적재된 데이터는 스캔 조건으로 검색하며, 저장(Put) 기능을 이용해 기적재한 데이터에 대해 칼럼 기반으로 수정|
|운전자의 운행 정보 중 30초를 기준으로 평균 속도가 80km/h를 초과한 정보는 분리 적재한다|에스퍼의 EPL에서 사용자별 운행 정보를 그루핑하고, 30초의 윈도우 타임(Window Time)조건으로 평균 시속 집계 및 임계치별 이벤트를 정의|
|과속한 차량을 분리 적재하기 위한 조건은 별도의 룰로 정의하고 쉽게 수정할 수 있어야 한다|과속 기준을 80km/h에서 100km/h로 변경해야 할 경우 EPL의 평균 속도를 체크하는 조건값만 수정|
|분리 적재한 데이터는 외부 애플리케이션이 빠르게 접근하고 조회할 수 있게 해야 한다.|실시간 이벤트로 감지된 데이터는 인메모리 기반 저장소인 레디스에 적재해서 외부 애플리케이션에서 빠르게 조회|
|레디스에 적재한 데이터는 저장소의 공간을 효율적으로 사용하기 위해 1주일이 경과하면 영구적으로 삭제한다|레디스 클라이언트 라이브러리인 제디스(jedis) 클라이언트를 이용해 데이터 적재 시 만료(Expire) 시간을 설정해 자동으로 영구 삭제 처리|

### 3.2. 작업 흐름도
위 세부 요구사항을 수행하기 위해 구축하고자 하는 아키텍처는 아래와 같다.

![pilotproject_plume_operation1](./images/pilotproject_workflow_tmp.png)

- 카프카 spout가 카프카에서 데이터를 로드하여, 에스퍼가 적용된 Bolt가 라우팅을 하여, 과속 차량을 판단한다.
- 과속 차량에 해당하는 경우, 운전자 정보를 레디스 Bolt에 전달하여, 레디스에 저장한다.
- 카프카로부터 로드한 모든 운전자 정보는 HBase Bolt에 전달되어, HBase에 저장한다.

### 3.2. 결과물









해당 단계가 가장 


