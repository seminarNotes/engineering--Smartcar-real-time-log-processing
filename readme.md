# Hadoop
최초 작성일 : 2024-01-23  
마지막 수정일 : 2024-01-23
  
## 0. Overview
<!--
<img src="./images/textbook.png" width="450" height="500" alt="Textbook">
-->

하둡(Hadoop)은 대규모 데이터 집합을 분산하여 처리하고 저장할 수 있는 오픈 소스 분산 컴퓨팅 프레임워크이다. 아파치 소프트웨어 재단에서 개발하고 관리하며, 빅데이터 처리와 저장을 위한 핵심 도구 중 하나이며, 하둡은 크게 두 가지 핵심 구성 요소로 구성되어 있습니다.

- Hadoop Distributed File System (HDFS)  
  HDFS는 대용량 데이터를 분산하여 저장하기 위한 파일 시스템이며, 이 파일 시스템은 데이터를 여러 노드에 나누어 저장하고, 데이터 손실을 방지하기 위한 복제 기능을 제공한다. 이를 통해 빅데이터를 안정적으로 저장하고 관리하는 데 중요한 역할을 수행한다.

- MapReduce
  MapReduce는 데이터를 처리하고 분석하는 데 사용되는 프로그래밍 모델과 프레임워크이다. MapReduce 작업은 두 단계로 나누어지는데, "맵" 단계에서 데이터를 분할하고 처리하며, "리듀스" 단계에서 중간 결과를 집계하고 최종 결과를 생성한다. 이 과정을 통해 병렬 처리와 분산 데이터 처리를 수행한다.

하둡은 하드웨어 클러스터를 활용하여 대용량 데이터를 효율적으로 처리하고 저장할 수 있는 기능을 제공한다. 이러한 특징으로 하둡은 대규모 데이터 처리, 데이터 분석, 머신러닝, 그리고 데이터 웨어하우스 등 다양한 빅데이터 작업에 사용된다. 또한 하둡 생태계는 다양한 관련 프로젝트와 도구를 포함하고 있어, 다양한 빅데이터 요구 사항에 맞게 확장하여 사용할 수 있다.

## Table of Contents

1. [Concept of Big Data](#1.-Concept-of-Big-Data)


## 1. Concept of Big Data
